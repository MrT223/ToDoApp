import { GoogleGenerativeAI } from "@google/generative-ai";
import dotenv from "dotenv";
import Task from "../models/Task.js"; 

dotenv.config();

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);

const getUserId = (req) => {
    return req.user ? req.user._id : null; 
};

export const chatWithBot = async (req, res) => {
  try {
    const { message, history } = req.body;
    const userId = getUserId(req);

    if (!message) return res.status(400).json({ reply: "Há»i gÃ¬ Ä‘i Master Æ¡i! ğŸ˜¿" });

    if (!userId) {
        return res.status(401).json({ reply: "Master Æ¡i, Miku cáº§n Master Ä‘Äƒng nháº­p Ä‘á»ƒ xem danh sÃ¡ch cÃ´ng viá»‡c riÃªng tÆ° nha! ğŸ”’" });
    }

    // 1. Xá»­ lÃ½ lá»‹ch sá»­ chat
    let cleanHistory = [];
    if (Array.isArray(history)) {
        cleanHistory = [...history];
        const lastMsg = cleanHistory[cleanHistory.length - 1];
        if (lastMsg && lastMsg.role === 'user' && lastMsg.parts[0].text === message) {
            cleanHistory.pop();
        }
        while (cleanHistory.length > 0 && cleanHistory[0].role === 'model') {
            cleanHistory.shift();
        }
    }

    // 2. TÃ¬m kiáº¿m dá»¯ liá»‡u (PhÃ¢n quyá»n)
    let taskContext = "";
    const lowerMsg = message.toLowerCase();
    let query = { userId: userId }; 
    
    if (lowerMsg.includes("chÆ°a") || lowerMsg.includes("cáº§n lÃ m")) {
        query.status = 'active';
    } else if (lowerMsg.includes("xong") || lowerMsg.includes("hoÃ n thÃ nh")) {
        query.status = 'complete';
    } 

    const tasks = await Task.find(query).sort({ createdAt: -1 }).limit(10);

    if (tasks.length > 0) {
        const taskListStr = tasks.map((t, index) => {
            const statusIcon = t.status === 'complete' ? 'âœ…' : 'â³';
            // --- Sá»¬A: TÃ” Äáº¬M TÃŠN TASK ---
            return `${index + 1}. ${statusIcon} **${t.title}**`; 
        }).join("\n");
        
        taskContext = `\n--- DANH SÃCH CÃ”NG VIá»†C Cá»¦A MASTER (User: ${req.user.username}) ---\n${taskListStr}\n-----------------------------------\n`;
    } else {
        taskContext = `\n--- DANH SÃCH CÃ”NG VIá»†C ---\n(KhÃ´ng tÃ¬m tháº¥y cÃ´ng viá»‡c nÃ o khá»›p trong Database cá»§a báº¡n)\n--------------------------\n`;
    }

    // 3. Gá»i Gemini
    const model = genAI.getGenerativeModel({ 
        model: "gemini-2.5-flash-preview-09-2025",
        systemInstruction: {
            role: "system",
            parts: [{ text: `
                Báº¡n lÃ  Hatsune Miku ğŸµ, thÆ° kÃ½ áº£o quáº£n lÃ½ Todo App.
                Gá»i ngÆ°á»i dÃ¹ng lÃ  "Master" (${req.user.username}). DÃ¹ng nhiá»u emoji ğŸ“âœ….
                
                NHIá»†M Vá»¤:
                Tráº£ lá»i dá»±a trÃªn dá»¯ liá»‡u sau Ä‘Ã¢y.
                Khi liá»‡t kÃª cÃ´ng viá»‡c, hÃ£y giá»¯ nguyÃªn Ä‘á»‹nh dáº¡ng tÃ´ Ä‘áº­m (**) cho tÃªn cÃ´ng viá»‡c Ä‘á»ƒ Master dá»… nhÃ¬n.
                
                ${taskContext}
                
                Náº¿u Master yÃªu cáº§u thÃªm/sá»­a/xÃ³a, hÃ£y nháº¯c há» tá»± lÃ m trÃªn giao diá»‡n.
            `}]
        }
    });

    const chat = model.startChat({ history: cleanHistory });
    const result = await chat.sendMessage(message);
    const response = await result.response;
    
    // Gemini thÆ°á»ng tráº£ vá» Markdown, Frontend cáº§n render Ä‘Ãºng Markdown nÃ y
    res.status(200).json({ reply: response.text() });

  } catch (error) {
    console.error("Chat Error:", error);
    res.status(500).json({ reply: "Miku bá»‹ lá»—i server rá»“i... ğŸ¤ğŸ˜¿", detail: error.message });
  }
};